[TOC]

# mysql汇总

## 存储引擎

<img src="/Users/cty/Library/Application Support/typora-user-images/image-20201022133302190.png" alt="image-20201022133302190" style="zoom:50%;" />

### MyISAM

不支持事务，也不支持外键。优势是访问的速度快，对事务完整性没有要求或者以select、insert为主的应用基本上都可以使用这个引擎来创建表。

每个MyISAM在磁盘上存储成3个文件，其文件名都和表名相同，但拓展名分别是：

.frm/存储表定义		.MYD/存储数据		.MYI/存储索引

数据文件和索引文件放在不同的谬，平均分布IO。MyISAM类型的表可能会损坏check table语句来检查，repair table语句修复。

MyISAM支持三种不同的存储格式，静态表、动态表、压缩表。

静态表的数据在存储时会按照列的宽度定义补足空格，但是在应用访问的时候并不会得到这些空格，这些空格在返回给应用之前已经去掉。

### InnoDB

InnoDB存储引擎提供了具有提交、回滚和崩溃回复能力的事务安全，但是和MySAIM的存储引擎相比，InnoDB写的处理效率差一些，并且会占用更多的磁盘空间来保留数据和索引。

##### 1.自动增长列auto_increment

LAST_INSERT_ID()查询当前线程最后插入记录使用的值。

##### 2.外键

在创建索引时，可以指定在删除、更新父表时，对子表进行的相应操作，包括restrict、cascade、set null和no action。

在导入多个表的数据时，如果需要忽略表之前的导入顺序，可以暂时关闭外键的检查；同样，在执行LOAD DATA和ALTER TABLE操作的时候，可以通过暂时关闭外键约束来加快处理的速度，关闭的命令是“SET FOREIGN_KEY_CHECKS = 0;”，执行完成之后，通过执行“SETFOREIGN_KEY_CHECKS = 1;”语句改回原状态。

##### 3.存储方式

1.使用共享表空间存储，这种方式创建的表的表结构保存在.frm文件中，数据和索引保存在innodb_data_home_dir和innodb_data_file_path定义的表空间中，可以是多个文件。

2.使用多表空间存储，这种方式创建的表的表结构仍然保存在.frm文件中，但是每个表的数据和索引单独保存在.ibd中。如果是个分区表，则每个分区对应单独的.ibd文件，文件名是“表名+分区名”，可以在创建分区的时候指定每个分区的数据文件的位置。

要使用多表空间的存储方式，需要设置参数innodb_file_per_tablle，并且重新启动服务后才可以生效，已有的表不会改变存储方式，多表空间的参数生效后，只对新建的表生效。

### MEMORY

MEMORY存储引擎使用存在于内存中的内容来创建表。每个MEMORY表只实际对应一个磁盘文件，格式是.frm。MEMORY类型的表访问非常得快，因为它的数据是放在内存中的，默认使用HASH索引，但是一旦服务关闭，表中的数据就会丢失。

### MERGE

MERGE存储引擎是一组MyISAM表的组合，这些MyISAM表必须结构完全相同，MERGE表本身并没有数据，对MERGE类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的MyISMAM表进行的。对于MERGE类型表的插入操作，是通过INSERT_METHOD子句定义插入的表，可以有3个不同的值，使用first或last值使得插入操作被相应地作用在第一或最后一个表上，不定义这个子句或者定义为NO，表示不能对这个MERGE表执行插入操作。MERGE表在磁盘上保留两个文件，文件名以表的名字开始，一个.frm文件存储表定义，另一个.MRG文件包含组合表的信息。

MERGE表并不能智能地将记录写到对应的表中，而分区表是可以的。通常我们使用MERGE表来透明地对多个表进行查询和更新操作，而对这种按照时间记录的操作日志表则可以透明地进行插入操作。

### TokuDB

第三方存储引擎，高性能支持事务的MySQL和MariaDB的存储引擎，具有高拓展性、高压缩率、高效的写入性能，支持大多数的在线DDL操作。

### 如何选择合适的存储引擎

MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除，并且对事务的完整性，并发行要求不是很高，那么选择这个存储引擎是非常合适的。是在web、数据仓库和其他应用环境下最常使用的存储引擎之一。

innoDB：用于事务处理应用程序，支持外键。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询以外，还包括很多的更新，删除操作，那么innoDB存储引擎是比较适合的选择。innoDB有效地降低由于删除和更新导致的锁定，还可以确保事务的完整提交和回滚，对于类似计费系统或者财务系统等对数据准确性要求比较高的系统，innoDB都是合适的选择。

MEMORY：将所有数据保存 在RAM中，在需要快速定位记录和其他类似数据的环境下，可提供极快的访问。MEMORY的缺陷是对表的大小有限制，太大的表无法缓存在内存中，其次是要确保表的数据可以恢复，数据库异常终止后表中的数据是可以恢复的。MEMORY表通常用于更新不太频繁的小表，用以快速得到访问结果。

MERGE：用于将一系列等同的MyISAM表以逻辑方式组合在一起，并作为一个对象引用它们。MERGE表的有点在于可以突破对单个MyISAM表大小的限制，并且通过将不同的表分布在多个磁盘上，可以有效地改善MERGE表的访问效率。对于诸如存储仓库等VLDB环境十分适合。



## 选择合适的数据类型

### char和varchar

innodb：建议使用varchar类型，对于innodb数据表，内部的行存储格式没有区分固定长度和可变长度列。所有数据行都使用指向数据列值的头指针，因此在本质上，使用固定长度的char列不一定比使用可变长度varchar列性能要好。因此，主要的性能因素是数据使用的存储总量。由于char平均占用的空间多余varchar，因此使用varchar来最小化需要处理的数据航的存储总量和磁盘IO是比较好的。

### text和blob

1.blob和text值会引起一些性能问题，特别是在执行了大量的删除操作时。删除操作会在数据表中留下很大的空洞，以后填入这些空洞的记录在插入的性能上会有影响，为了提高性能，建议定期使用OPTIMIZE TABLE功能对这类表进行碎片整理，避免因为空洞导致性能问题。

2.可以使用合成的Synthetic索引来提高大文本字段的查询性能。

3.不必要的时候避免检索大型的blob或text

4.把blob或text列分离到单独的表中

### 浮点数和定点数

decimal/numberic表示定点数。

### 日期类型选择

如果要记录年月日时分秒，并且记录的年份比较久远，那么最好使用 DATETIME，而不要使用TIMESTAMP。因为TIMESTAMP表示的日期范围比DATETIME要短得多。如果记录的日期需要让不同时区的用户使用，那么最好使用TIMESTAMP，因为日期类型中只有它能够和实际时区相对应





## 视图

下面列出一些比较常用的视图。

SCHEMATA：该表提供了当前mysql实例中所有数据库的信息，show databases的结果取之此表。

TABLES：该表提供了关于数据库中的表的信息（包括视图），详细表述了某个表属于哪个schema、表类型、表引擎、创建时间等信息。show tables from schemaname的结果取之此表。

COLUMNS：该表提供了表中的列信息，详细表述了某张表的所有列以及每个列的信息。showcolumns from schemaname.tablename的结果取之此表。

STATISTICS：该表提供了关于表索引的信息。show index from schemaname.tablename的结果取之此表。

MySQL 创建或使用视图常见的规则与限制有：

- 必须唯一命名；
- 视图数目没有限制；
- 视图可以嵌套；
- ORDER BY可以在视图中使用，但如果从该视图检索数据SELECT中也含有ORDER BY，那么该视图的ORDER BY将被覆盖；
- 视图不能索引，不能有关联的触发器或默认值；
- 视图可以和表一起使用，如编写一条联接表和视图的SELECT语句；
- 在FROM 关键字后面不能包含子查询。

其中WITH [CASCADED | LOCAL] CHECK OPTION 决定了是否允许更新数据使记录不再满足视图的条件：

- LOCAL 是只要满足本视图的条件就可以更新；
- CASCADED （默认）则是必须满足所有针对该视图的所有视图的条件才可以更新。如果1，2，3中，2带有check，只会对1，2进行check，3的条件不会进行check。

1.利用视图，简化复杂联接

2.用视图过滤不想要的数据

3.使用视图与计算字段

4.WITH [CASCADED | LOCAL] CHECK OPTION的使用

以下类型的视图是不可更新的。

- 包含以下关键字的SQL 语句：聚合函数（SUM,MIN,MAX,COUNT 等）,DISTINCT,GROUP BY,HAVING,JOIN,UNION ,UNION ALL;
- 常量视图;
- SELECT 中包含子查询
- FROM 一个不能更新的视图;
- WHERE 字句的子查询引用了FROM 字句中的表.

## 存储过程

存储过程和函数是事先经过编译并存储在数据库中的一段sql语句的集合，存储过程和函数的区别在于函数必须有返回值，而存储过程没有。





## 触发器



## 事务控制和锁定

## mysql事务

mysql：事务与锁

https://developer.ibm.com/zh/technologies/databases/articles/os-mysql-transaction-isolation-levels-and-locks/

https://developer.ibm.com/zh/technologies/databases/articles/os-mysql-transaction-isolation-levels-and-locks/#行锁的算法

在面试中，基本上都会问到关于数据库的事务问题，如果啥都不会或者只回答到表面的上知识点的话，那面试基本上是没戏了，为了能顺利通过面试，那MySql的事务问题就需要了解，所以就根据网上的资料总结一版Mysql事务的知识点，巩固一下事务的知识。

事务是指逻辑上的一组操作，要么都执行，要么都不执行,

### 事务的特性（ACID）

- 原子性(`Atomicity`)：事务是不可分割的工作单元，要么都成功，要么都失败， 如果事务中一个sql语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态。
- 一致性(`Consistency`)：事务不能破坏数据的完整性和业务的一致性 。例如在银行转账时，不管事务成功还是失败，双方钱的总额不变
- 隔离性(`Isolation`)：一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般是不可见）
- 持久性(`Durability`)：事务提交之后，所做的修改就会永久保存，不会因为系统故障导致数据丢失

严格来说，只有同时满足数据库的事务ACID特性才能算一个完整的事务，但现实中实现能够真正满足的完整的事务特性少之又少，但是在实现中也必须尽量达到事务要求的特性。

那么事务ACID特性具体怎么实现的呢？我们来分析看看，首先先看看事务的特性。

------

### 原子性(`Atomicity`)

首先我们来看看事务的原子性特性，看看其如何实现的？

原子性(`Atomicity`)：事务是不可分割的工作单元，要么都成功，要么都失败， 如果事务中一个sql语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态

原子性(`Atomicity`)的实现离不开 MySQL的事务日志 `undo log`日志类型，当事务需要回滚的时候需要将数据库状态回滚到事务开始前，即需要撤销所有已经成功执行的sql语句。那么`undo log`起了关键性作用：

**当事务对数据库进行修改时，InnoDB会生成对应的`undo log`****；如果事务执行失败或调用了`rollback`****，导致事务需要回滚，便可以利用`undo log`****中的信息将数据回滚到修改之前的样子。**

那么`undo log`是什么呢？每个数据变更操作是怎么被记录下来的呢？

### undo log（ 回滚日志 ）

`undo log` (回滚日志)：是采用**段(`segment`****)**的方式来记录的，每个`undo`操作在记录的时候占用一个**`undo log segment`**。为什么会在数据更改操作的时候，记录了相对应的`undo log`呢？其目的在于：

- 为了保证数据的原子性，记录事务发生之前的一个版本，用于回滚，
- 通过`mvcc`+`undo log`实现innodb事务可重复读和读取已提交隔离级别。

其中，`undo log`分为：

- `insert undo log`：`insert`操作中产生的`undo log`，
- `update undo log`：对`delete` 和`update`操作产生的`undo log` 

数据更改的`undo log`怎么记录的呢？

 因为`insert`操作的记录，只对事务本身可见，对其他事务不可见。故该`undo log`可以在事务提交后直接删除，不需要进行`purge`操作，

 而`Delete`操作在事务中实际上并不是真正的删除掉数据行，而是一种Delete Mark操作，在记录上标识`Delete_Bit`，而不删除记录。是一种"假删除",只是做了个标记，真正的删除工作需要后台`purge`线程去完成。

`update`分为两种情况：`update`的列是否是主键列。

- 如果不是主键列，在`undo log`中直接反向记录是如何`update`的。即`update`是直接进行的。
- 如果是主键列，`update`分两部执行：先删除该行，再插入一行目标行。

与`insert undo log`不同的，`update undo log`日志，当事务提交的时候，innodb不会立即删除`undo log`， 会将该事务对应的`undo log`放入到删除列表中，未来通过`purge`线程来删除。

因为后续还可能会用到`undo log`，如隔离级别为`repeatable read`时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除（即`undo log`不能删除）,且`undo log`分配的页可重用减少存储空间和提升性能。 

> Note：purge线程两个主要作用是：清理undo页和清除page里面带有Delete_Bit标识的数据行。

 

接着我们来看看事务的隔离性，看看事务有哪些隔离级别，而且事务并发中会产生什么问题。

------

### 隔离性(`Isolation`)

隔离性(`Isolation`)，是指事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰 ，一个事务所操作的数据在提交之前，对其他事务的可见性设定(一般是不可见)。

### 事务隔离级别

而且数据库为了在并发下有效保证读取数据正确性，数据库提供了四种事务隔离级别>，分别为：

- 读未提交(**脏读**)：允许读取尚未提交的数据，允许脏读
- 读已提交（ **不可重复读** ）：允许读取事务已经提交的数据
- 可重复读（ **幻读** ）：在同一个事务内的查询结果都是和事务开始时刻查询一致的（ InnoDB默认级别 ）
- 串行化：所有事务逐个依次执行， 每次读都需要获得表级共享锁，读写相互都会阻塞

其中，不同的隔离级别可能会存在在不同并发问题，主要并发问题包括：

- **数据丢失：** 两个或多个事务操作相同数据，基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新

- **脏读：**读到了其他事务还未提交的数据，事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据

    

    ![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmmXvxnaQq5p8dQSTj5K8EMicF2c6WyBkFbQfOSzcbq6jk8YJGFcOh46g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- **不可重复读（重点是修改）：**在一个事务中，先后进行两次相同的读取，由于另一个事务修改了数据，导致前后两次结果的不一致，事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

    

    ![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFm6tdicD2HjhvRXibhXCtTn6rH5cLPuicuexv7oH3wYibnBrovbvo4JHxvkw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- **幻读（重点是新增、删除）：** 在一个事务中，先后进行两次相同的读取（一般是范围查询），由于另一个事务新增或删除了数据，导致前后两次结果不一致

    

    ![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFm4d2C0AiaquwswcPdYyLxc9hTiamoyVbgdozoCSmNBmj2dvbykQyrZkdQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 不可重复读和幻读的区别？
>
> 不可重复读和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题，
>
> 使用锁机制来实现这两种隔离级别，在可重复读中，相同sql第一次读取到数据后就将这些数据加锁，其它事务无法更新操作这些数据来实现可重复读了隔离。
>
> 但这种处理方式却无法锁住insert的数据，因此会出现当事务A先前读取了数据，事务B再`insert`数据提交，结果发现事务A就会发现莫名其妙多了些数据，这就是幻读，不能通过行锁来避免 。

了解了并发问题后，来看看不同的隔离级别可能会存在在不同并发问题：

| 事务隔离级别 | 脏读 | 不可重复读 | 幻读 |
| ------------ | ---- | ---------- | ---- |
| 读未提交     | 是   | 是         | 是   |
| 不可重复读   | 否   | 是         | 是   |
| 可重复读     | 否   | 否         | 是   |
| 串行化       | 否   | 否         | 否   |

为了实现事务隔离，延伸出了数据库锁。其中，**innodb事务的隔离级别是由锁机制和MVCC（多版本并发控制）来实现的**

那我们来先看看锁的原理，怎么使用锁来实现事务隔离的呢？

### 锁机制

锁机制的基本工作原理，事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁，

MySQL主要分成三种类型（级别）的锁机制：

- 表级锁：最大颗粒度的锁机制，锁定资源争用的概率也会最高 ，并发度最低 ，但开销小，加锁快，不会出现死锁，
- 行级锁：最大颗粒度的锁机制很小， 发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能 ，但 开销大，加锁慢；会出现死锁 ，
- 页级锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

而且不同的存储引擎支持不同的的锁机制，主要分析一下InnoDB锁。

#### InnoDB锁

 InnoDB实现了以下两种类型的行锁

- 共享锁（S锁、行锁）：多个事务对同一数据行可以共享一把锁，只能读不能修改
- 排它锁（X锁、行锁）：一个事务获取一个数据行的排它锁，那么其他事务将不能再获取该行的锁（共享锁、排它锁）， 允许获取排他锁的事务更新数据

对于`UPDATE`,`DELETE`,`INSERT`操作， InnoDB会自动给涉及及数据集加排他锁（Ｘ）；对于普通SELECT语句，InnoDB不会加任何锁,

而且因为InnoDB引擎允许行锁和表锁共存，实现多粒度锁机制，使用意向锁实现表锁机制，

- 意向共享锁（IS锁、表锁）：当事务准备给**数据行**加共享锁时，会先给**表**加上一个意向共享锁。意向共享锁之间是兼容的
- 意向排它锁（IX锁、表锁）：当事务准备给数据行加排它锁时，会先给表加上一个意向排它锁。意向排它锁之间是兼容的

意向锁(IS、IX)是InnoDB数据操作之前自动加的，不需要用户干预。它的意义在于：当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁，否则就需要等待，

其中，四种锁的兼容性如下

| 当前锁模式/是否兼容/请求锁模式 | X    | IX   | S    | IS   |
| ------------------------------ | ---- | ---- | ---- | ---- |
| X                              | 冲突 | 冲突 | 冲突 | 冲突 |
| IX                             | 冲突 | 兼容 | 冲突 | 兼容 |
| S                              | 冲突 | 冲突 | 兼容 | 兼容 |
| IS                             | 冲突 | 兼容 | 兼容 | 兼容 |

如果一个事务请求的锁模式与当前的锁兼容，InnoDB就请求的锁授予该事务；反之，如果两者两者不兼容，该事务就要等待锁释放。

#### InnoDB行锁

InnoDB的行锁是通过给索引上的**索引项加锁**来实现的。**只有通过索引检索数据，才能使用行锁，否则将使用表锁（锁住索引的所有记录）**

innodb的行锁，默认是由**`临键锁(next-key)`**算法实现的，可以防止幻读。根据索引，划分为一个个**左开右闭**的区间。当进行范围查询的时候，若命中索引且能够检索到数据，则锁住记录所在的区间和它的下一个区间,

其实，**临键锁(Next-Key)**=**记录锁(Record Locks)**+**间隙锁(Gap Locks)**，

- 当我们用范围条件检索数据而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合范围条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做间隙(GAP)。
- 当使用唯一索引，且记录存在的精准查询时，使用**Record Locks记录锁**

具体的使用体现在哪里呢？如下图所示：

- 范围查询，记录存在

![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmIvTG2Z905QUWVJgL5KYvySqTVgJf3licqul9aCZgbMvlFthtOpTYVww/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 当记录不存在（不论是等值查询，还是范围查询）时，next-key将退化成**Gap Lock（间隙锁）**

     

    ![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmWpbMHJ8rEpFJyCiaa9vZGXPUsvricjWr0KxzQzHPyickY8zibqNLb6OemQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 当条件是精准匹配（即为等值查询时）且记录存在时，并且是唯一索引，**临键锁(Next-Key)**退化成**Record Lock（记录锁）**

     

    ![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmsdCoFtlnGsncibWh7DLGCDy9lsEjbJsgKISMUpKVkcauW4Fuibd54L0w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 当条件是精准匹配（即为等值查询时）且记录存在，但不是唯一索引时，**临键锁(Next-Key)**会有精准值的数据会增加**Record Lock（记录锁）**和精准值前后的区间的数据会增加**Gap Lock（间隙锁)**。

    

    ![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmz0VibbGWM6LPXzu6v2WfxfX41Xuo26h2StJrzu0GMpjtSojga6nbSVA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 如何使用锁解决并发问题

利用锁解决脏读、不可重复读、幻读

- X锁解决脏读
- S锁解决不可重复读
- 临键锁解决幻读

#### `Multiversion concurrency control` (`MVCC` 多版本并发控制)

`InnoDB`的`MVCC`是通过在每行记录后面保存两个隐藏的列来实现的，**一个保存了行的事务ID（事务ID就会递增 ）**，**一个保存了行的回滚段的指针** 。

 

![img](https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmR7uEiaSiaIwwML2kqPjwfcejNLV9I5qJrznHCtAhl7n3l6NiaDuMNCgGg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

每开始一个新的事务，都会自动递增产 生一个新的事务id。事务开始时刻的会把事务id放到当前事务影响的行事务id中，而`DB_ROLL_PTR`表示指向该行回滚段的指针，该行记录上所有版本数据，在undo中都通过链表形式组织，该值实际指向undo中该行的历史记录链表，

在并发访问数据库时，对正在事务中的数据做MVCC多版本的管理，以避免写操作阻塞读操作，并且会通过比较版本解决幻读。

而且MVCC只在`REPEATABLE READ`和`READ COMMITIED`两个隔离级别下才会工作，**其中，MVCC实现实质就是保存数据在某个时间点的快照来实现的。** 那哪些操作是快照读？

#### 快照读和当前读

**快照读**，innodb快照读，数据的读取将由 cache(原本数据) + undo(事务修改前的数据) 两部分组成

- 普通的`select`，比如 `select * from table where ?`;

**当前读**，SQL读取的数据是最新版本。通过锁机制来保证读取的数据无法通过其他事务进行修改

- `UPDATE`

- `DELETE`

- `INSERT`

- `SELECT … LOCK IN SHARE MODE`

- `SELECT … FOR UPDATE`

    其中当前读中，只有`SELECT … LOCK IN SHARE MODE`对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。

那么在RR隔离级别下，MVCC具体是如何操作的。

#### RR隔离级别下，MVCC具体操作

**SELECT操作**，InnoDB遵循以后两个规则执行：

1. InnoDB只查找版本早于当前事务版本的数据行（即行的事务编号小于或等于当前事务的事务编号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的记录。
2. 行的删除版本要么未定义,读取到事务开始之前状态的版本>,这可以确保事务读取到的行，在事务开始之前未被删除.只有同时满足的两者的记录，才能返回作为查询结果.

**INSERT**：InnoDB为新插入的每一行保存当前事务编号作为行版本号。

**DELETE**：InnoDB为删除的每一行保存当前事务编号作为行删除标识。

**UPDATE**：InnoDB为插入一行新记录，保存当前事务编号作为行版本号，同时保存当前事务编号到原来的行作为行删除标识>。

保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。	

分析完了原子性和隔离性，我们继续看看事务的持久性。



### 持久性(`Durability`)

持久性(`Durability`)：事务提交之后，所做的修改就会永久保存，不会因为系统故障导致数据丢失，

而且其实现的关键在于`redo log`， 在执行SQL时会保存已执行的SQL语句到一个指定的Log文件，当执行`recovery`时重新执行`redo log`记录的SQL操作。

那么`redo log`如何实现的呢？

### redo log

当向数据库写入数据时，执行过程会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏），这整一过程称为redo log。redo log 分为：

-  Buffer Pool内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；
- 磁盘上的重做日志文件(redo log file)，该部分日志是持久的。

Buffer Pool的使用可以大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据在内存还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

为了确保事务的持久性，在当事务提交时，会调用`fsync`接口对`redo log`进行刷盘, （即`redo log buffer`写日志到磁盘的`redo log file`中 ）,刷新频率由 `innodb_flush_log_at_trx_commit`变量来控制的：

- 0 ：每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据 ；
- 1：事务每次提交都写入磁盘；
- 2：每秒刷新写入到磁盘中的，但跟0是有区别的。

redo log有更加详细的解读，后续有时间再补上，到现在为止，已经将事务三个特性都理解了，那事务一致性呢？

------

### 一致性(`Consistency`)

一致性(`Consistency`)：事务不能破坏数据的完整性和业务的一致性 ：

- 数据的完整性：实体完整性、列完整性（如字段的类型、大小、长度要符合要求）、外键约束等

- 业务的一致性：例如在银行转账时，不管事务成功还是失败，双方钱的总额不变。

那是如何保证数据一致性的？

其实数据一致性是通过事务的原子性、持久性和隔离性来保证的

- 原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log
- 持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log
- 隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）

### 总结

其中要同时满足ACID特性，这样的事务少之又少。实际中很多例子都只是满足一些特性，比如：

- MySQL的NDB Cluster事务不满足持久性和隔离性；
- InnoDB默认事务隔离级别是可重复读，不满足隔离性；
- Oracle默认的事务隔离级别为READ COMMITTED，不满足隔离性

所以我们只能使用这个四个维度的特性去衡量事务的操作。



## mysql锁机制

锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。锁是Mysql在服务器层和存储引擎层的的并发控制。 

加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否是否已解除、释放锁等。 

### **锁机制**

#### **共享锁与排他锁**

- 共享锁（读锁）：其他事务可以读，但不能写。
- 排他锁（写锁） ：其他事务不能读取，也不能写。

#### **粒度锁**

MySQL 不同的存储引擎支持不同的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现： 

- MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking）
- BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁
- InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。

默认情况下，表锁和行锁都是自动获得的， 不需要额外的命令。 

但是在有的情况下， 用户需要明确地进行锁表或者进行事务的控制， 以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。

#### **不同粒度锁的比较：**

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 

- - 这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁。
    - 表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如Web 应用

- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

- - 最大程度的支持并发，同时也带来了最大的锁开销。
    - 在 InnoDB 中，除单个 SQL 组成的事务外，
        锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的。
    - 行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统

- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

### **MyISAM 表锁**

#### **MyISAM表级锁模式：** 

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。 

默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。 （This ensures that updates to a table are not “starved” even when there is heavy SELECT activity for the table. However, if there are many updates for a table, SELECT statements wait until there are no more updates.）。

这也正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。同时，一些需要长时间运行的查询操作，也会使写线程“饿死” ，应用中应尽量避免出现长时间运行的查询操作（在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解” ，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行）。

可以设置改变读锁和写锁的优先级： 

- 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。 
- 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。 
- 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。
- 给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。

#### **MyISAM加表锁方法：**

MyISAM 在执行查询语句（SELECT）前，会自动给涉及的表加读锁，在执行更新操作
（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。

在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。 



MyISAM存储引擎支持并发插入，以减少给定表的读和写操作之间的争用：

如果MyISAM表在数据文件中间没有空闲块，则行始终插入数据文件的末尾。 在这种情况下，你可以自由混合并发使用MyISAM表的INSERT和SELECT语句而不需要加锁——你可以在其他线程进行读操作的时候，同时将行插入到MyISAM表中。 文件中间的空闲块可能是从表格中间删除或更新的行而产生的。 如果文件中间有空闲快，则并发插入会被禁用，但是当所有空闲块都填充有新数据时，它又会自动重新启用。 要控制此行为，可以使用MySQL的concurrent_insert系统变量。

如果你使用LOCK TABLES显式获取表锁，则可以请求READ LOCAL锁而不是READ锁，以便在锁定表时，其他会话可以使用并发插入。

- 当concurrent_insert设置为0时，不允许并发插入。 
- 当concurrent_insert设置为1时，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个线程读表的同时，另一个线程从表尾插入记录。这也是MySQL的默认设置。 
- 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。

#### **查询表级锁争用情况：**

可以通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况：

```text
mysql> SHOW STATUS LIKE 'Table%';
+-----------------------+---------+
| Variable_name | Value |
+-----------------------+---------+
| Table_locks_immediate | 1151552 |
| Table_locks_waited | 15324 |
+-----------------------+---------+
```

### **InnoDB行级锁和表级锁**

#### **InnoDB锁模式：**

InnoDB 实现了以下两种类型的**行锁**： 

- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 
- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。 
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

**锁模式的兼容情况：**

![img](https://pic4.zhimg.com/80/v2-37761612ead11ddc3762a4c20ddab3f3_1440w.jpg)

（如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务； 反之， 如果两者不兼容，该事务就要等待锁释放。）

#### **InnoDB加锁方法：**

- 意向锁是 InnoDB 自动加的， 不需用户干预。 

- 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB
    会自动给涉及数据集加排他锁（X)；

- 对于普通 SELECT 语句，InnoDB 不会加任何锁；
    事务可以通过以下语句显式给记录集加共享锁或排他锁：

- - 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。
    - 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁



- **隐式锁定：**

InnoDB在事务执行过程中，使用两阶段锁协议：

随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；

锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在**同一时刻**被释放。 

- **显式锁定 ：**

```text
select ... lock in share mode //共享锁 
select ... for update //排他锁 
```

**select for update：**

在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。

select *** for update 的使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。

**select lock in share mode ：**in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。select *** lock in share mode 使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。

**性能影响：**
select for update 语句，相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。
select lock in share mode 语句是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。

**for update 和 lock in share mode 的区别：**

前一个上的是排他锁（X 锁），一旦一个事务获取了这个锁，其他的事务是没法在这些数据上执行 for update ；后一个是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。

#### **InnoDB 行锁实现方式：**

- InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！
- 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。
- 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，
    别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。（更多阅读：[MySQL索引总结](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s/h4B84UmzAUJ81iBY_FXNOg)）
- 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。

#### **InnoDB的间隙锁：**

当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。 

**InnoDB使用间隙锁的目的：**

1. 防止幻读，以满足相关隔离级别的要求；
2. 满足恢复和复制的需要：

MySQL 通过 BINLOG 录入执行成功的 INSERT、UPDATE、DELETE 等更新数据的 SQL 语句，并由此实现 MySQL 数据库的恢复和主从复制。MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点：

一是 MySQL 的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中的 SQL 语句。

二是 MySQL 的 Binlog 是按照事务提交的先后顺序记录的， 恢复也是按这个顺序进行的。

由此可见，MySQL 的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。

#### **InnoDB 在不同隔离级别下的一致性读及锁的差异：**

锁和多版本数据（MVCC）是 InnoDB 实现一致性读和 ISO/ANSI SQL92 隔离级别的手段。

因此，在不同的隔离级别下，InnoDB 处理 SQL 时采用的一致性读策略和需要的锁是不同的：

![img](https://pic2.zhimg.com/80/v2-c83c6459f8dc93a5f157fe1e3080088d_1440w.jpg)



![img](https://pic1.zhimg.com/80/v2-568951f4cdfeb9416042627a7b94c4ac_1440w.jpg)



对于许多 SQL，隔离级别越高，InnoDB 给记录集加的锁就越严格（尤其是使用范围条件的时候），产生锁冲突的可能性也就越高，从而对并发性事务处理性能的 影响也就越大。 

因此， 我们在应用中， 应该尽量使用较低的隔离级别， 以减少锁争用的机率。实际上，通过优化事务逻辑，大部分应用使用 Read Commited 隔离级别就足够了。对于一些确实需要更高隔离级别的事务， 可以通过在程序中执行 SET SESSION TRANSACTION ISOLATION 

LEVEL REPEATABLE READ 或 SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE 动态改变隔离级别的方式满足需求。

#### **获取 InnoDB 行锁争用情况：**

可以通过检查 InnoDB_row_lock 状态变量来分析系统上的行锁的争夺情况：

```text
mysql> show status like 'innodb_row_lock%'; 
+-------------------------------+-------+ 
| Variable_name | Value | 
+-------------------------------+-------+ 
| InnoDB_row_lock_current_waits | 0 | 
| InnoDB_row_lock_time | 0 | 
| InnoDB_row_lock_time_avg | 0 | 
| InnoDB_row_lock_time_max | 0 | 
| InnoDB_row_lock_waits | 0 | 
+-------------------------------+-------+ 
5 rows in set (0.01 sec)
```

### **LOCK TABLES 和 UNLOCK TABLES**

Mysql也支持lock tables和unlock tables，这都是在服务器层（MySQL Server层）实现的，和存储引擎无关，它们有自己的用途，并不能替代事务处理。 （除了禁用了autocommint后可以使用，其他情况不建议使用）： 

- LOCK TABLES 可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。 
- UNLOCK TABLES 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES 时，
    或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁

#### **LOCK TABLES语法：**

- 在用 LOCK TABLES 对 InnoDB 表加锁时要注意，要将 AUTOCOMMIT 设为 0，否则MySQL 不会给表加锁；
- 事务结束前，不要用 UNLOCK TABLES 释放表锁，因为 UNLOCK TABLES会隐含地提交事务；
- COMMIT 或 ROLLBACK 并不能释放用 LOCK TABLES 加的表级锁，必须用UNLOCK TABLES 释放表锁。

正确的方式见如下语句：
例如，如果需要写表 t1 并从表 t 读，可以按如下做：

```text
SET AUTOCOMMIT=0; 
LOCK TABLES t1 WRITE, t2 READ, ...; 
[do something with tables t1 and t2 here]; 
COMMIT; 
UNLOCK TABLES;
```

#### **使用LOCK TABLES的场景：**

给表显示加表级锁（InnoDB表和MyISAM都可以），一般是为了在一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。（与MyISAM默认的表锁行为类似）

在用 LOCK TABLES 给表显式加表锁时，必须同时取得所有涉及到表的锁，并且 MySQL 不支持锁升级。也就是说，在执行 LOCK TABLES 后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。

其实，在MyISAM自动加锁（表锁）的情况下也大致如此，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。

例如，有一个订单表 orders，其中记录有各订单的总金额 total，同时还有一个 订单明细表 order_detail，其中记录有各订单每一产品的金额小计 subtotal，假设我们需要检 查这两个表的金额合计是否相符，可能就需要执行如下两条 SQL： 

```text
Select sum(total) from orders; 
Select sum(subtotal) from order_detail; 
```

这时，如果不先给两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，
order_detail 表可能已经发生了改变。因此，正确的方法应该是： 

```text
Lock tables orders read local, order_detail read local; 
Select sum(total) from orders; 
Select sum(subtotal) from order_detail; 
Unlock tables;
```

（在 LOCK TABLES 时加了“local”选项，其作用就是允许当你持有表的读锁时，其他用户可以在满足 MyISAM 表并发插入条件的情况下，在表尾并发插入记录（MyISAM 存储引擎支持“并发插入”））

### **死锁（Deadlock Free）**

- **死锁产生：**

- - 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。 
    - 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。 
    - 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

- **检测死锁：**数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。

- **死锁恢复：**死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。 

- **外部锁的死锁检测：**发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决 

- **死锁影响性能：**死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。 

#### **MyISAM避免死锁：**

- 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

#### **InnoDB避免死锁：**

- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。 
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁
- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。
- 改变事务隔离级别

如果出现死锁，可以用 SHOW INNODB STATUS 命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

### **一些优化锁性能的建议**

- 尽量使用较低的隔离级别； 
- 精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会
- 选择合理的事务大小，小事务发生锁冲突的几率也更小
- 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁
- 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会
- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- 除非必须，查询时不要显示加锁。 MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能；MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作
- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能

#### **乐观锁、悲观锁**

- **乐观锁(Optimistic Lock)**：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。

乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。

- **悲观锁(Pessimistic Lock)**：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。

悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。



```text
参考：
《高性能MySQL》
《深入浅出MySQL》
http://www.cnblogs.com/liushuiwuqing/p/3966898.html  
https://dev.mysql.com/doc/refman/5.7/en/internal-locking.html 
http://www.cnblogs.com/0201zcr/p/4782283.html 
```



## 索引原理

### 索引的优缺点

#### **优点**

- 索引大大减小了服务器需要扫描的数据量

- 索引可以帮助服务器避免排序和临时表

- 索引可以将随机IO变成顺序IO

- 索引对于InnoDB（对索引支持行级锁）非常重要，因为它可以让查询锁更少的元组。在MySQL5.1和更新的版本中，InnoDB可以在服务器端过滤掉行后就释放锁，但在早期的MySQL版本中，InnoDB直到事务提交时才会解锁。对不需要的元组的加锁，会增加锁的开销，降低并发性。  InnoDB仅对需要访问的元组加锁，而索引能够减少InnoDB访问的元组数。但是只有在存储引擎层过滤掉那些不需要的数据才能达到这种目的。一旦索引不允许InnoDB那样做（即索引达不到过滤的目的），MySQL服务器只能对InnoDB返回的数据进行WHERE操作，此时，已经无法避免对那些元组加锁了。如果查询不能使用索引，MySQL会进行全表扫描，并锁住每一个元组，不管是否真正需要。

- - 关于InnoDB、索引和锁：InnoDB在二级索引上使用共享锁（读锁），但访问主键索引需要排他锁（写锁）

#### **缺点**

- 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存索引文件。
- 建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。
- 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。
- 对于非常小的表，大部分情况下简单的全表扫描更高效；

索引只是提高效率的一个因素，如果你的MySQL有大数据量的表，就需要花时间研究建立最优秀的索引，或优化查询语句。
因此应该只为最经常查询和最经常排序的数据列建立索引。

MySQL里同一个数据表里的索引总数限制为16个。

### **索引存储类型**

#### **B-Tree索引**

InnoDB使用的是B+Tree

B+Tree：每一个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的范围遍历。

B+Tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同，很适合查找范围数据。

B-Tree可以对<，<=，=，>，>=，BETWEEN，IN，以及不以通配符开始的LIKE使用索引。

##### **索引查询**

可以利用B-Tree索引进行全关键字、关键字范围和关键字前缀查询，但必须保证按索引的最左边前缀(leftmost prefix of the index)来进行查询。



![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuT4fBAOcXbNSUk7ymf3zU0rgWoNYGL5QFaxFia75SUtweIFUibVlBht4zg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

假设有如下一个表：



![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTzKSGfibdTMJEd4V9rPej0oUbpqVYkHZCgsxmBqHUhEv4tyicN1SxeStw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

其组合索引包含表中每一行的last_name、first_name和dob列。其结构大致如下：



![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuT6hibgxk5E2V4pSyqMhHem3lV6RjW9Hv7rEU52mlsvgSc212h3x3qiaFw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

按索引的最左边前缀(leftmost prefix of the index)来进行查询：

1. 查询必须从索引的最左边的列开始，否则无法使用索引。例如，你不能直接利用索引查找在某一天出生的人。
2. 不能跳过某一索引列。例如，你不能利用索引查找last name为Smith且出生于某一天的人。
3. 存储引擎不能使用索引中范围条件右边的列。例如，如果你的查询语句为WHERE last_name="Smith" AND first_name LIKE 'J%' AND dob='1976-12-23'，则该查询只会使用索引中的前两列，因为LIKE是范围查询。



1. 匹配全值(Match the full value)：对索引中的所有列都指定具体的值。例如，上图中索引可以帮助你查找出生于1960-01-01的Cuba Allen。
2. 匹配最左前缀(Match a leftmost prefix)：你可以利用索引查找last name为Allen的人，仅仅使用索引中的第1列。
3. 匹配列前缀(Match a column prefix)：例如，你可以利用索引查找last name以J开始的人，这仅仅使用索引中的第1列。
4. 匹配值的范围查询(Match a range of values)：可以利用索引查找last name在Allen和Barrymore之间的人，仅仅使用索引中第1列。
5. 匹配部分精确而其它部分进行范围匹配(Match one part exactly and match a range on another part)：可以利用索引查找last name为Allen，而first name以字母K开始的人。
6. 仅对索引进行查询(Index-only queries)：如果查询的列都位于索引中，则不需要再多一次I/O回读元组。(覆盖索引：索引的叶子节点中已经包含要查询的数据，那么就没有必要再回表查询了，如果索引包含满足查询的所有数据，就称为覆盖索引。)

##### **索引排序**

也可以利用B-Tree索引进行索引排序（对查询结果进行ORDER BY），必须保证ORDER BY按索引的最左边前缀(leftmost prefix of the index)来进行。



MySQL中，有两种方式生成有序结果集：

- 使用filesort
- 按索引顺序扫描

如果explain出来的type列的值为“index”，则说明MYSQL使用了索引扫描来做排序。

**按索引顺序扫描：**



可以利用同一索引同时进行查找和排序操作：

- 当索引的顺序与ORDER BY中的列顺序相同，且所有的列是同一方向（全部升序或者全部降序）时，可以使用索引来排序。
- ORDER BY子句和查询型子句的限制是一样的：需要满足索引的最左前缀的要求，有一种情况下ORDER BY子句可以不满足索引的最左前缀要求，那就是前导列为常量时：WHERE子句或者JOIN子句中对前导列指定了常量。![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTKA4bag54FjInQm5wVCYFgO22aBWiaqiac7T0CoRXHOK4rkBl63ryqW3g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
- 如果查询是连接多个表，仅当ORDER BY中的所有列都是第一个表的列时才会使用索引。其它情况都会使用filesort文件排序。

###### **使用filesort：**

当MySQL不能使用索引进行排序时，就会利用自己的排序算法(快速排序算法)在内存(sort buffer)中对数据进行排序；如果内存装载不下，它会将磁盘上的数据进行分块，再对各个数据块进行排序，然后将各个块合并成有序的结果集（实际上就是外排序，使用临时表）。

对于**filesort**，MySQL有两种排序算法：

- **两次扫描算法(Two passes)**

先将需要排序的字段和可以直接定位到相关行数据的指针信息取出，然后在设定的内存（通过参数sort_buffer_size设定）中进行排序，完成排序之后再次通过行指针信息取出所需的Columns。

该算法是MySQL4.1之前采用的算法，它需要两次访问数据，尤其是第二次读取操作会导致大量的随机I/O操作。另一方面，内存开销较小。

- **一次扫描算法(single pass)**

该算法一次性将所需的Columns全部取出，在内存中排序后直接将结果输出。
从MySQL4.1版本开始使用该算法。它减少了I/O的次数，效率较高，但是内存开销也较大。如果我们将并不需要的Columns也取出来，就会极大地浪费排序过程所需要的内存。

在 MySQL 4.1 之后的版本中，可以通过设置 max_length_for_sort_data 参数来控制 MySQL 选择第一种排序算法还是第二种：当取出的所有大字段总大小大于 max_length_for_sort_data 的设置时，MySQL 就会选择使用第一种排序算法，反之，则会选择第二种。

当对连接操作进行排序时，如果ORDER BY仅仅引用第一个表的列，MySQL对该表进行filesort操作，然后进行连接处理，此时，EXPLAIN输出“Using filesort”；否则，MySQL必须将查询的结果集生成一个临时表，在连接完成之后进行filesort操作，此时，EXPLAIN输出“Using temporary;Using filesort”。

为了尽可能地提高排序性能，我们自然更希望使用第二种排序算法，所以在 Query 中仅仅取出需要的 Columns 是非常有必要的。

##### **聚簇索引(cluster index)**

一个表只能有一个聚簇索引。

目前，只有solidDB和InnoDB支持聚簇索引，MyISAM不支持聚簇索引。一些DBMS允许用户指定聚簇索引，但是MySQL的存储引擎到目前为止都不支持。

###### **InnoDB的聚簇索引：**

1. InnoDB对主键建立聚簇索引。
2. 如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。
3. 如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。

InnoDB默认使用聚簇索引来组织数据，如果你用InnoDB，而且不需要特殊的聚簇索引，一个好的做法就是使用代理主键(surrogate key)——独立于你的应用中的数据。最简单的做法就是使用一个AUTO_INCREMENT的列，这会保证记录按照顺序插入，而且能提高使用primary key进行连接的查询的性能。应该尽量避免随机的聚簇主键，例如字符串主键就是一个不好的选择，它使得插入操作变得随机。

一般来说，DBMS都会以聚簇索引的形式来存储实际的数据，它是其它二级索引的基础：

- 聚簇索引（primary索引）：主键索引
- 非聚簇索引（second索引）：二级索引

###### **聚簇索引结构：**

聚簇索引的结构大致如下：

- **聚簇索引：**节点页只包含了索引列，叶子页包含了行的全部数据。聚簇索引“就是表”，因此可以不需要独立的行存储。

聚簇索引保证关键字的值相近的元组存储的物理位置也相近（所以字符串类型不宜建立聚簇索引，特别是随机字符串，会使得系统进行大量的移动操作）。



![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTQqWgzkf5VhX4I7FblPePpkcIV2FibbLZPWgLjArSibsCaS3abY7gvbqw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- **二级索引：**叶子节点保存的不是指行的物理位置的指针，而是行的主键值。

这意味着通过二级索引查找行，存储引擎需要：1、找到二级索引的叶子节点获取对应的主键值，2、根据这个主键值去聚簇索引中查找到对应的行。这里需要两次B-Tree查找而不是一次。

覆盖索引对于InnoDB表尤其有用，因为InnoDB使用聚簇索引组织数据，如果二级索引中包含查询所需的数据，就不再需要在聚集索引中查找了。

###### **聚簇索引（InnoDB）和二级索引（MyISAM）数据布局比较：**



![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTzib3QSYketg5uPMcLicTAlqOu9Yia4sJoNmJjyjRkLeAB2m0xw10otAZg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- **MyISAM**

MyISAM按照插入的顺序在磁盘上存储数据：

左边为行号(row number)，从0开始。因为元组的大小固定，所以MyISAM可以很容易的从表的开始位置找到某一字节的位置。

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuToWI86EY3geLmpmqNc7X7PSsa0sWoc2KhUGgF5GYO30bceBeibS8uJUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

MyISAM建立的索引结构大致如下：

**col1主键索引：**

MyISAM不支持聚簇索引，索引中每一个叶子节点仅仅包含行号(row number)，且叶子节点按照col1的顺序存储。





![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuThibfmqcRHoMQr6WlCEibkpHoricHGRoocuyC6aw9jKicjqExFZRl2vL69g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**col2非主键索引：**

在MyISAM中，primary key和其它索引没有什么区别。Primary key仅仅只是一个叫做PRIMARY的唯一，非空的索引而已，叶子节点按照col2的顺序存储。

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTiay0M5LNgh3tF19nHFNJtycUiaia0D07Ld7caVP5lGjzhF6Yu2ibo3tLng/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- **InnoDB**

**col1主键索引，即聚簇索引：**

聚簇索引中的每个叶子节点包含主键的值，事务ID，用于事务和MVCC的回滚指针，和余下的列(如col2)。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

**col2非主键索引，即二级索引：**

InnoDB的二级索引的叶子包含主键的值，而不是行指针(row pointers)，这样的策略减小了移动数据或者数据页面分裂时维护二级索引的开销，因为InnoDB不需要更新索引的行指针。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

- **聚簇索引+二级索引表 与 非聚簇索引表 的对比**

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTNnqfaPVQxLbnOvxxZQiccgeup5gqRnjjBenWJYr3wibXQgYQnf7UNibQQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### **Hash索引**

哈希索引基于哈希表实现，只有精确索引所有列的查询才有效。

对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据的指针。

MySQL中，只有Memory存储引擎显示支持hash索引，是Memory表的默认索引类型，尽管Memory表也可以使用B-Tree索引。

Memory存储引擎支持非唯一hash索引，这在数据库领域是罕见的：如果多个值有相同的hash code，索引把它们的行指针用链表保存到同一个hash表项中。

假设创建如下一个表：

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTJjV0s7udaAEl4FsWicS9UL25b6ByeiceSOYTu6LNRicvFM0dyKNpxHvMA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

包含的数据如下：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

假设索引使用hash函数f( )，如下：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

此时，索引的结构大概如下：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

哈希索引中存储的是：哈希值+数据行指针 
当你执行 SELECT lname FROM testhash WHERE fname='Peter';  MySQL会计算’Peter’的hash值，然后通过它来查询索引的行指针。因为f('Peter') = 8784，MySQL会在索引中查找8784，得到指向记录3的指针。

**Hash索引有以下一些限制：**

- 由于索引仅包含hash code和记录指针，所以，MySQL不能通过使用索引避免读取记录，即每次使用哈希索引查询到记录指针后都要回读元祖查取数据。
- 不能使用hash索引排序。
- Hash索引不支持键的部分匹配，因为是通过整个索引值来计算hash值的。
- Hash索引只支持等值比较，例如使用=，IN( )和<=>。对于WHERE price>100并不能加速查询。
- 访问Hash索引的速度非常快，除非有很多哈希冲突（不同的索引列值却有相同的哈希值）。当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行。
- 如果哈希冲突很多的话，一些索引维护操作的代价也会很高。当从表中删除一行时，存储引擎要遍历对应哈希值的链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。



InnoDB引擎有一个特殊的功能叫做“自适应哈希索引”，由Mysql自动管理，不需要DBA人为干预。默认情况下为开启，我们可以通过参数innodb_adaptive_hash_index来禁用此特性。

当InnoDB注意到某些索引值被使用得非常频繁时，它会在内存中基于缓冲池中的B+ Tree索引上再创建一个哈希索引，这样就上B-Tree索引也具有哈希索引的一些优点，比如快速的哈希查找。

- 只能用于等值比较，例如=， <=>，in  ；
- 无法用于排序

InnoDB官方文档显示，启用自适应哈希索引后，读和写性能可以提高2倍，对于辅助索引的连接操作，性能可以提高5倍

#### **空间(R-Tree)索引**

MyISAM支持空间索引，主要用于地理空间数据类型，例如GEOMETRY。

#### **全文(Full-text)索引**

全文索引是MyISAM的一个特殊索引类型，它查找的是文本中的关键词，主要用于全文检索。

### **索引使用**

#### **MySQL建立索引类型**

- 单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。
- 组合索引，即一个索包含多个列。

索引是在存储引擎中实现的，而不是在服务器层中实现的。所以，每种存储引擎的索引都不一定完全相同，并不是所有的存储引擎都支持所有的索引类型。

#### **普通索引**

这是最基本的索引，它没有任何限制。普通索引（由关键字KEY或INDEX定义的索引）的唯一任务是加快对数据的访问速度。因此，应该只为那些最经常出现在查询条件(WHERE column = …)或排序条件(ORDER BY column)中的数据列创建索引。
它有以下几种创建方式：

- 创建索引

CREATE INDEX indexName ON mytable(username(length)); 

如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length，下同。

- 修改表结构

ALTER mytable ADD INDEX [indexName] ON (username(length))

- 创建表的时候直接指定

CREATE TABLE mytable(  ID INT NOT NULL,   username VARCHAR(16) NOT NULL,  INDEX[indexName] (username(length))  ); 

- 删除索引的语法：

DROP INDEX [indexName] ON mytable;

**唯一索引**

它与前面的普通索引类似，不同的就是：普通索引允许被索引的数据列包含重复的值。而唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。

它有以下几种创建方式：

- 创建索引

CREATE UNIQUE INDEX indexName ON mytable(username(length))

- 修改表结构

ALTER mytable ADD UNIQUE [indexName] ON (username(length))

- 创建表的时候直接指定

CREATE TABLE mytable(  ID INT NOT NULL,   username VARCHAR(16) NOT NULL,  UNIQUE [indexName] (username(length))  ); 

**主键索引**

它是一种特殊的唯一索引，不允许有空值。一个表只能有一个主键。

一般是在建表的时候同时创建主键索引：
CREATE TABLE mytable(  ID INT NOT NULL,   username VARCHAR(16) NOT NULL,  PRIMARY KEY(ID)  );  当然也可以用 ALTER 命令。

与之类似的，外键索引：如果为某个外键字段定义了一个外键约束条件，MySQL就会定义一个内部索引来帮助自己以最有效率的方式去管理和使用外键约束条件。

**组合索引**

为了形象地对比单列索引和组合索引，为表添加多个字段：
CREATE TABLE mytable(  ID INT NOT NULL,   username VARCHAR(16) NOT NULL,  city VARCHAR(50) NOT NULL,  age INT NOT NULL  ); 

为了进一步榨取MySQL的效率，就要考虑建立组合索引。就是将 name, city, age建到一个索引里：
ALTER TABLE mytable ADD INDEX name_city_age (name(10),city,age); 

建表时，usernname长度为 16，这里用 10。这是因为一般情况下名字的长度不会超过10，这样会加速索引查询速度，还会减少索引文件的大小，提高INSERT的更新速度。

建立这样的组合索引，其实是相当于分别建立了下面三组组合索引：

usernname,city,age 

usernname,city 

usernname 

为什么没有 city，age这样的组合索引呢？这是因为MySQL组合索引“最左前缀”的结果。简单的理解就是只从最左面的开始组合。并不是只要包含这三列的查询都会用到该组合索引。下面的几个SQL就会用到这个组合索引：

SELECT * FROM mytable WHREE username="admin" AND city="郑州" 
SELECT * FROM mytable WHREE username="admin"
而下面几个则不会用到：
SELECT * FROM mytable WHREE age=20 AND city="郑州" 
SELECT * FROM mytable WHREE city="郑州"

如果分别在 usernname，city，age上建立单列索引，让该表有3个单列索引，查询时和上述的组合索引效率也会大不一样，远远低于我们的组合索引。因为虽然此时有了三个索引，但MySQL只能用到其中的那个它认为似乎是最有效率的单列索引。

**建立索引的时机**

一般来说，在WHERE和JOIN中出现的列需要建立索引，但也不完全如此，因为MySQL的B-Tree只对<，<=，=，>，>=，BETWEEN，IN，以及不以通配符开始的LIKE才会使用索引。

例如：
SELECT t.Name  FROM mytable t LEFT JOIN mytable m   ON t.Name=m.username WHEREm.age=20 AND m.city='郑州' 

此时就需要对city和age建立索引，由于mytable表的userame也出现在了JOIN子句中，也有对它建立索引的必要。

#### **正确使用索引**

使用（B-Tree）索引时，有以下一些技巧和注意事项：

##### **索引设计：**

- 索引字段尽量使用数字型（简单的数据类型）

若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了

- 尽量不要让字段的默认值为NULL



在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。

索引不会包含有NULL值的列，只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。

所以我们在数据库设计时尽量不要让字段的默认值为NULL，应该指定列为NOT NULL，除非你想存储NULL。你应该用0、一个特殊的值或者一个空串代替空值。

- 前缀索引和索引选择性

对串列进行索引，如果可能应该指定一个前缀长度。

对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MYSQL不允许索引这些列的完整长度。

前缀索引是一种能使索引更小、更快的有效办法，但另一方面也有其缺点：MySQL无法使用前缀索引做order by和group by，也无法使用前缀索引做覆盖扫描。

一般情况下某个前缀的选择性也是足够高的，足以满足查询性能。

例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。

短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。在绝大多数应用里，数据库中的字符串数据大都以各种各样的名字为主，把索引的长度设置为10~15个字符已经足以把搜索范围缩小到很少的几条数据记录了。

通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性。

索引的选择性是指，不重复的索引值（基数）和数据表中的记录总数的比值。索引的选择性越高则查询效率越高，因为选择性高的索引可以让MYSQL在查找时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。
决窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。前缀应该足够长，以使得前缀索引的选择性接近于索引整个列。换句话说，前缀的“基数”应该接近于完整列的“基数”。

为了决定前缀的合适长度，需要找到最常见的值的列表，然后和最常见的前缀列表进行比较。例如以下查询：
select count(*) as cnt,city from sakila.city_demo group by city order by cnt desc limit 10;
select count(*) as cnt,left(city,7) as perf  from sakila.city_demo group by city order by cnt desc limit 10;
直到这个前缀的选择性接近完整列的选择性。
计算合适的前缀长度的另一个方法就是计算完整列的选择性，并使前缀的选择性接近于完整列的选择性，如下：
select  count(distinct city)/count(*) from sakila.city_demo;
select  count(distinct left(city,7))/count(*) from sakila.city_demo;

- 使用唯一索引

考虑某列中值的分布。索引的列的基数越大，索引的效果越好。

例如，存放出生日期的列具有不同值，很容易区分各行。而用来记录性别的列，只含有“ M” 和“F”，则对此列进行索引没有多大用处，因为不管搜索哪个值，都会得出大约一半的行。

- 使用组合索引代替多个列索引

一个多列索引（组合索引）与多个列索引MySQL在解析执行上是不一样的，如果在explain中看到有索引合并（即MySQL为多个列索引合并优化），应该好好检查一下查询的表和结构是不是已经最优。

- 注意重复/冗余的索引、不使用的索引

MySQL允许在相同的列上创建多个索引，无论是有意还是无意的。大多数情况下不需要使用冗余索引。

对于重复/冗余、不使用的索引：可以直接删除这些索引。因为这些索引需要占用物理空间，并且也会影响更新表的性能。

##### **索引使用：**

- 如果对大的文本进行搜索，使用全文索引而不要用使用 like ‘%…%’
- like语句不要以通配符开头

对于LIKE：在以通配符%和_开头作查询时，MySQL不会使用索引。like操作一般在全文索引中会用到（InnoDB数据表不支持全文索引）。
例如下句会使用索引：
SELECT * FROM mytable WHERE username like'admin%'
而下句就不会使用：
SELECT * FROM mytable WHEREt Name like'%admin' 

- 不要在列上进行运算



索引列不能是表达式的一部分，也不是是函数的参数。

例如以下两个查询无法使用索引：
1）表达式：  select actor_id from sakila.actor where actor_id+1=5;
2）函数参数：select ... where TO_DAYS(CURRENT_DATE) - TO_DAYS(date_col)<=10;

- 尽量不要使用NOT IN、<>、!= 操作



应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。

对于not in，可以用not exists或者（外联结+判断为空）来代替；很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b) 用下面的语句替换： select num from a where exists(select 1 from b where num=a.num)
对于<>，用其它相同功能的操作运算代替，如a<>0 改为 a>0 or a<0

- or条件

用 or 分割开的条件， 如果 or 前的条件中的列有索引， 而后面的列中没有索引， 那么涉及到的索引都不会被用到

应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num=10 or num=20 可以这样查询： select id from t where num=10 union all select id from t where num=20

- 组合索引的使用要遵守“最左前缀”原则'

组合索引：当不需要考虑排序和分组时，将选择性最高的列放在前面通常是最好的。

例子：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

1. 查询必须从索引的最左边的列开始，否则无法使用索引。例如，你不能直接利用索引查找在某一天出生的人。
2. 不能跳过某一索引列。例如，你不能利用索引查找last name为Smith且出生于某一天的人。
3. 存储引擎不能使用索引中范围条件右边的列。例如，如果你的查询语句为WHERE last_name="Smith" AND first_name LIKE 'J%' AND dob='1976-12-23'，则该查询只会使用索引中的前两列，因为LIKE是范围查询。

- 使用索引排序时，ORDER BY也要遵守“最左前缀”原则



1. 当索引的顺序与ORDER BY中的列顺序相同，且所有的列是同一方向（全部升序或者全部降序）时，可以使用索引来排序。
2. ORDER BY子句和查询型子句的限制是一样的：需要满足索引的最左前缀的要求，有一种情况下ORDER BY子句可以不满足索引的最左前缀要求，那就是前导列为常量时：WHERE子句或者JOIN子句中对前导列指定了常量。
3. 如果查询是连接多个表，仅当ORDER BY中的所有列都是第一个表的列时才会使用索引。其它情况都会使用filesort文件排序。![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTKA4bag54FjInQm5wVCYFgO22aBWiaqiac7T0CoRXHOK4rkBl63ryqW3g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



- 如果列类型是字符串，那么一定记得在 where 条件中把字符常量值用引号引起来，否则的话即便这个列上有索引，MySQL 也不会用到的，因为MySQL 默认把输入的常量值进行转换以后才进行检索。 例如：

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTaMlZFAzH863nS37JNn6icxdqdlUZk2ibwPLHicpkIUCxf86LbsHL4voXA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTCZwcK4pZGlLPMt964VXX8jcbUaamibicfdmibiaqZWa9yfKUvN0xN3m0gw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段

- 如果 MySQL 估计使用索引比全表扫描更慢，则不使用索引。当索引列有大量数据重复时,查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。

***\*索引性能测试与索引优化\****

只有当数据库里已经有了足够多的测试数据时，它的性能测试结果才有实际参考价值。如果在测试数据库里只有几百条数据记录，它们往往在执行完第一条查询命令之后就被全部加载到内存里，这将使后续的查询命令都执行得非常快——不管有没有使用索引。只有当数据库里的记录超过了1000条、数据总量也超过了 MySQL服务器上的内存总量时，数据库的性能测试结果才有意义。

在不确定应该在哪些数据列上创建索引的时候，人们从EXPLAIN SELECT命令那里往往可以获得一些帮助。这其实只是简单地给一条普通的SELECT命令加一个EXPLAIN关键字作为前缀而已。有了这个关键字，MySQL将不是去执行那条SELECT命令，而是去对它进行分析。MySQL将以表格的形式把查询的执行过程和用到的索引(如果有的话)等信息列出来。

**查看索引使用情况：**

- 如果索引正在工作，Handler_read_key 的值将很高，这个值代表了一个行被索引值读的次数，很低的值表明增加索引得到的性能改善不高，因为索引并不经常使用。 
- Handler_read_rnd_next 的值高则意味着查询运行低效，并且应该建立索引补救。这个值的含义是在数据文件中读下一行的请求数。如果正进行大量的表扫描， Handler_read_rnd_next 的值较高，则通常说明表索引不正确或写入的查询没有利用索引。

具体如下：

![img](http://mmbiz.qpic.cn/mmbiz_png/B4NbFWic0yX0JFONaicAb8zdzibBbgfGfuTj9m6SqY6blJwBBkDt4Kz3Dk0v5jntJdqTzbDzyComquoEXXDicec6aA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

从上面的例子中可以看出，目前使用的 MySQL 数据库的索引情况并不理想。

参考资料：

《深入浅出MySQL》

《高性能MySQL》

http://blog.csdn.net/xifeijian/article/details/20557921 

http://blog.csdn.net/xlgen157387/article/details/44156679 
